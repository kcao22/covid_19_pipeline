{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from helper_functions import create_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating IAM Role with Glue full access and S3 full access. Required for crawler to function properly\n",
    "session = create_session()\n",
    "iam = session.client('iam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create role for Glue to assume, provide access to Glue and S3 in subsequent step\n",
    "assume_role_policy_document = json.dumps({\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [\n",
    "                            {\n",
    "                                \"Effect\": \"Allow\",\n",
    "                                \"Principal\": {\n",
    "                                \"Service\": \"glue.amazonaws.com\"\n",
    "                                },\n",
    "                            \"Action\": \"sts:AssumeRole\"\n",
    "                            }\n",
    "                        ]\n",
    "                    })\n",
    "try:\n",
    "    res = iam.create_role(\n",
    "        RoleName='covid-project-glue-s3',\n",
    "        AssumeRolePolicyDocument=assume_role_policy_document\n",
    "        )\n",
    "    print(f'Status Code: {res[\"ResponseMetadata\"][\"HTTPStatusCode\"]}')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach policies\n",
    "try:\n",
    "    policies = [\n",
    "        'arn:aws:iam::aws:policy/AmazonS3FullAccess',  #S3 Full Access\n",
    "        'arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole',  #Glue Service Role\n",
    "        'arn:aws:iam::aws:policy/AWSGlueConsoleFullAccess'  #Glue Console Full Access\n",
    "    ]\n",
    "    for policy in policies:\n",
    "        res = iam.attach_role_policy(\n",
    "            RoleName='covid-project-glue-s3',\n",
    "            PolicyArn=policy\n",
    "        )\n",
    "        print(f'Policy: {policy}\\nStatus Code: {res[\"ResponseMetadata\"][\"HTTPStatusCode\"]}')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate glue client object\n",
    "glue = session.client('glue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create glue database for crawlers to save glue catalog tables / schemas to\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue/client/create_database.html\n",
    "# From documentation, default permissions typically not used in normal course of Glue operations.\n",
    "try:\n",
    "    res = glue.create_database(\n",
    "        DatabaseInput={\n",
    "            'Name':'aws-covid-project',\n",
    "            'Description': 'Database for housing crawled schema of datasets from AWS Covid-19 Data Lake'\n",
    "        }\n",
    "    )\n",
    "    print(f'Status Code: {res[\"ResponseMetadata\"][\"HTTPStatusCode\"]}')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw/enigma-jhu/enigma-jhu',\n",
       " 'raw/enigma-nyt-usa-counties/enigma-nyt-usa-counties',\n",
       " 'raw/enigma-nyt-usa-states/enigma-nyt-usa-states',\n",
       " 'raw/rearc-states-daily-test/rearc-states-daily-test',\n",
       " 'raw/rearc-usa-daily-test/rearc-usa-daily-test',\n",
       " 'raw/rearc-usa-hospital-beds/rearc-usa-hospital-beds',\n",
       " 'raw/rearc-usa-latest-total/rearc-usa-latest-total',\n",
       " 'raw/static-country-codes/static-country-codes',\n",
       " 'raw/static-county-codes/static-county-codes',\n",
       " 'raw/static-state-codes/static-state-codes']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = session.client('s3')\n",
    "[file_path['Key'] for file_path in s3.list_objects(Bucket='kc-covid-project')['Contents'] if file_path['Key'].startswith('raw')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enigma-jhu\n",
      "Status Code: 200\n",
      "\n",
      "enigma-nyt-usa-counties\n",
      "Status Code: 200\n",
      "\n",
      "enigma-nyt-usa-states\n",
      "Status Code: 200\n",
      "\n",
      "rearc-states-daily-test\n",
      "Status Code: 200\n",
      "\n",
      "rearc-usa-daily-test\n",
      "Status Code: 200\n",
      "\n",
      "rearc-usa-hospital-beds\n",
      "Status Code: 200\n",
      "\n",
      "rearc-usa-latest-total\n",
      "Status Code: 200\n",
      "\n",
      "static-country-codes\n",
      "Status Code: 200\n",
      "\n",
      "static-county-codes\n",
      "Status Code: 200\n",
      "\n",
      "static-state-codes\n",
      "Status Code: 200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create glue crawlers and attach above created policy to each crawler for Glue / S3 full access\n",
    "\n",
    "# Get Role ARN\n",
    "role_arn = None\n",
    "for role in iam.list_roles()['Roles']:\n",
    "    if role['RoleName'] == 'covid-project-glue-s3':\n",
    "        role_arn = role['Arn']\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "try:\n",
    "    # Store necessary parameters in variables for each target object in S3\n",
    "    s3 = session.client('s3')\n",
    "    bucket_name = 'kc-covid-project'\n",
    "    database_name = 'aws-covid-project'\n",
    "\n",
    "    for obj in s3.list_objects(Bucket=bucket_name)['Contents']:\n",
    "        if 'raw' in obj['Key']:\n",
    "            obj_key = obj['Key'].split('/')[-1]\n",
    "            # S3 path must be to file's parent directory and not to the file itself\n",
    "            s3_path = f's3://{bucket_name}/raw/{obj_key}'\n",
    "\n",
    "            # Create crawler for each if crawler does not exist\n",
    "            if obj_key not in glue.list_crawlers()['CrawlerNames']:\n",
    "                # For static_state_codes, all cols are string types. Need to create classifier for crawler so that first row headers are identified\n",
    "                if obj_key not in ['raw/static-state-codes/static-state-codes']:\n",
    "                    res = glue.create_crawler(\n",
    "                        Name=obj_key,\n",
    "                        Role=role_arn,\n",
    "                        DatabaseName=database_name,\n",
    "                        Description=f'Crawler for {obj_key} dataset from AWS Covid-19 Data Lake',\n",
    "                        Targets={\n",
    "                            'S3Targets': [\n",
    "                                {\n",
    "                                'Path': s3_path\n",
    "                                }\n",
    "                            ]\n",
    "                        },\n",
    "                        Classifiers=['static_state_classifier']\n",
    "                        SchemaChangePolicy={\n",
    "                            'UpdateBehavior': 'LOG',\n",
    "                            'DeleteBehavior': 'LOG'\n",
    "                        },\n",
    "                        RecrawlPolicy={\n",
    "                            'RecrawlBehavior':'CRAWL_EVERYTHING'\n",
    "                        },\n",
    "                        LineageConfiguration={\n",
    "                            'CrawlerLineageSettings': 'DISABLE'\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    glue.create_classifier(\n",
    "                        CsvClassifier={\n",
    "                            'Name': 'static_state_classifier',\n",
    "                            'Delimiter': ',',\n",
    "                            'QuoteSymbol': '\"',\n",
    "                            'ContainsHeader': 'PRESENT',\n",
    "                            'Header': ['State', 'Abbreviation']\n",
    "                        }\n",
    "                    )\n",
    "                    res = glue.create_crawler(\n",
    "                        Name=obj_key,\n",
    "                        Role=role_arn,\n",
    "                        DatabaseName=database_name,\n",
    "                        Description=f'Crawler for {obj_key} dataset from AWS Covid-19 Data Lake',\n",
    "                        Targets={\n",
    "                            'S3Targets': [\n",
    "                                {\n",
    "                                'Path': s3_path\n",
    "                                }\n",
    "                            ]\n",
    "                        },\n",
    "                        Classifiers=['static_state_classifier']\n",
    "                        SchemaChangePolicy={\n",
    "                            'UpdateBehavior': 'LOG',\n",
    "                            'DeleteBehavior': 'LOG'\n",
    "                        },\n",
    "                        RecrawlPolicy={\n",
    "                            'RecrawlBehavior':'CRAWL_EVERYTHING'\n",
    "                        },\n",
    "                        LineageConfiguration={\n",
    "                            'CrawlerLineageSettings': 'DISABLE'\n",
    "                        }\n",
    "                    )\n",
    "                print(obj_key)\n",
    "                print(f'Status Code: {res[\"ResponseMetadata\"][\"HTTPStatusCode\"]}\\n')\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enigma-jhu\n",
      "Status Code: 200\n",
      "\n",
      "enigma-nyt-usa-counties\n",
      "Status Code: 200\n",
      "\n",
      "enigma-nyt-usa-states\n",
      "Status Code: 200\n",
      "\n",
      "rearc-states-daily-test\n",
      "Status Code: 200\n",
      "\n",
      "rearc-usa-daily-test\n",
      "Status Code: 200\n",
      "\n",
      "rearc-usa-hospital-beds\n",
      "Status Code: 200\n",
      "\n",
      "rearc-usa-latest-total\n",
      "Status Code: 200\n",
      "\n",
      "static-country-codes\n",
      "Status Code: 200\n",
      "\n",
      "static-county-codes\n",
      "Status Code: 200\n",
      "\n",
      "static-state-codes\n",
      "Status Code: 200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run crawlers\n",
    "try:\n",
    "    for crawler in glue.list_crawlers()['CrawlerNames']:\n",
    "        res = glue.start_crawler(\n",
    "            Name=crawler\n",
    "        )\n",
    "        print(crawler)\n",
    "        print(f'Status Code: {res[\"ResponseMetadata\"][\"HTTPStatusCode\"]}\\n')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awscovid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
